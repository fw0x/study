# 《深入剖析 Kubernetes》学习笔记 Day 9

今天继续学习Kubernetes集群搭建与实践 (3讲)的第2讲，坑填起来了！

**前文回顾**

部署 Master 节点，还有 1 个 kubelet 报错没解决：

- The kubelet is not running
- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)

**从 0 到 1 搭建一个完整的 Kubernetes 集群**

安装 kubeadm 较低版本，与作者安装的 k8s 版本保持一致：

```
apt remove kubelet kubectl kubeadm
apt install kubelet=1.11.3-00
apt install kubectl=1.11.3-00
apt install kubeadm=1.11.3-00
```

报错1:  kubeadm : Depends: kubernetes-cni (= 0.6.0)

```
# apt install kubeadm=1.11.3-00
Reading package lists... Done
Building dependency tree
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies:
 kubeadm : Depends: kubernetes-cni (= 0.6.0)
```

```
# 查看 kubernetes-cni 可以安装的版本：
apt-cache policy kubernetes-cni

apt-get install kubernetes-cni=0.6.0-00
```

再一次 `kubeadm init --config kubeadm.yam`

报错：

```
[preflight] Some fatal errors occurred:
	[ERROR Swap]: running with swap on is not supported. Please disable swap
	[ERROR SystemVerification]: unsupported docker version: 18.09.7
```

解决办法：

```
# 禁用 swap
swapoff -a

# 降级 docker 版本
apt remove docker.io
apt-cache policy docker-ce
apt install docker-ce=17.03.3~ce-0~ubuntu-xenial
```

如果 docker 版本过高，会报错

```
	[WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.06.3-ce. Max validated version: 17.03
```

拉取镜像报错：

```
# kubeadm config images pull
failed to pull image "k8s.gcr.io/kube-apiserver-amd64:v1.11.10": exit status 1
```

查看 kubeadm 拉取镜像仓库

```
# kubeadm config images list
k8s.gcr.io/kube-apiserver-amd64:v1.11.10
k8s.gcr.io/kube-controller-manager-amd64:v1.11.10
k8s.gcr.io/kube-scheduler-amd64:v1.11.10
k8s.gcr.io/kube-proxy-amd64:v1.11.10
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd-amd64:3.2.18
k8s.gcr.io/coredns:1.1.3
```

修改 aliyuncs 镜像仓库名 REPOSITORY：

```
# docker images
REPOSITORY                                                              TAG                 IMAGE ID            CREATED             SIZE
registry.aliyuncs.com/google_containers/kube-proxy-amd64                v1.11.10            6d859c5ba087        3 years ago         97.4 MB
registry.aliyuncs.com/google_containers/kube-controller-manager-amd64   v1.11.10            3eb89ae87afc        3 years ago         156 MB
registry.aliyuncs.com/google_containers/kube-apiserver-amd64            v1.11.10            b2e25e147ed1        3 years ago         187 MB
registry.aliyuncs.com/google_containers/kube-scheduler-amd64            v1.11.10            b91e0e16786e        3 years ago         56.9 MB
registry.aliyuncs.com/google_containers/coredns                         1.1.3               b3b94275d97c        4 years ago         45.6 MB
registry.aliyuncs.com/google_containers/etcd-amd64                      3.2.18              b8df3b177be2        4 years ago         219 MB
registry.aliyuncs.com/google_containers/pause                           3.1                 da86e6ba6ca1        5 years ago         742 kB
```

```
docker tag registry.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.10 k8s.gcr.io/kube-proxy-amd64:v1.11.10
docker tag registry.aliyuncs.com/google_containers/kube-controller-manager-amd64:v1.11.10 k8s.gcr.io/kube-controller-manager-amd64:v1.11.10
docker tag registry.aliyuncs.com/google_containers/kube-scheduler-amd64:v1.11.10 k8s.gcr.io/kube-scheduler-amd64:v1.11.10
docker tag registry.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.10 k8s.gcr.io/kube-proxy-amd64:v1.11.10
docker tag registry.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1
docker tag registry.aliyuncs.com/google_containers/etcd-amd64:3.2.18 k8s.gcr.io/etcd-amd64:3.2.18
docker tag registry.aliyuncs.com/google_containers/coredns:1.1.3 k8s.gcr.io/coredns:1.1.3
```

再来！ `kubeadm init --config kubeadm.yam`

```
# kubeadm init --config kubeadm.yaml --v=5
I0124 09:05:14.900373   54148 masterconfig.go:113] loading configuration from the given file
I0124 09:05:14.902134   54148 interface.go:360] Looking for default routes with IPv4 addresses
I0124 09:05:14.902163   54148 interface.go:365] Default route transits interface "ens33"
I0124 09:05:14.902367   54148 interface.go:174] Interface ens33 is up
I0124 09:05:14.902432   54148 interface.go:222] Interface "ens33" has 2 addresses :[192.168.31.73/24 fe80::20c:29ff:fee0:9006/64].
I0124 09:05:14.902464   54148 interface.go:189] Checking addr  192.168.31.73/24.
I0124 09:05:14.902471   54148 interface.go:196] IP found 192.168.31.73
I0124 09:05:14.902480   54148 interface.go:228] Found valid IPv4 address 192.168.31.73 for interface "ens33".
I0124 09:05:14.902485   54148 interface.go:371] Found active IP 192.168.31.73
I0124 09:05:15.524880   54148 feature_gate.go:230] feature gates: &{map[]}
I0124 09:05:15.524926   54148 init.go:250] [init] validating feature gates
[init] using Kubernetes version: v1.11.10
[preflight] running pre-flight checks
I0124 09:05:15.524964   54148 checks.go:581] validating kubernetes and kubeadm version
I0124 09:05:15.524982   54148 checks.go:179] validating if the firewall is enabled and active
I0124 09:05:15.529338   54148 checks.go:216] validating availability of port 6443
I0124 09:05:15.529421   54148 checks.go:216] validating availability of port 10251
I0124 09:05:15.529459   54148 checks.go:216] validating availability of port 10252
I0124 09:05:15.529493   54148 checks.go:291] validating the existence of file /etc/kubernetes/manifests/kube-apiserver.yaml
I0124 09:05:15.529517   54148 checks.go:291] validating the existence of file /etc/kubernetes/manifests/kube-controller-manager.yaml
I0124 09:05:15.529524   54148 checks.go:291] validating the existence of file /etc/kubernetes/manifests/kube-scheduler.yaml
I0124 09:05:15.529541   54148 checks.go:291] validating the existence of file /etc/kubernetes/manifests/etcd.yaml
I0124 09:05:15.529548   54148 checks.go:438] validating if the connectivity type is via proxy or direct
I0124 09:05:15.529574   54148 checks.go:474] validating http connectivity to first IP address in the CIDR
I0124 09:05:15.529586   54148 checks.go:474] validating http connectivity to first IP address in the CIDR
I0124 09:05:15.529590   54148 checks.go:138] validating if the service is enabled and active
I0124 09:05:15.539472   54148 checks.go:340] validating the contents of file /proc/sys/net/bridge/bridge-nf-call-iptables
I0124 09:05:15.539735   54148 checks.go:340] validating the contents of file /proc/sys/net/ipv4/ip_forward
I0124 09:05:15.539866   54148 checks.go:653] validating whether swap is enabled or not
I0124 09:05:15.539991   54148 checks.go:381] validating the presence of executable crictl
I0124 09:05:15.540015   54148 checks.go:381] validating the presence of executable ip
I0124 09:05:15.540032   54148 checks.go:381] validating the presence of executable iptables
I0124 09:05:15.540137   54148 checks.go:381] validating the presence of executable mount
I0124 09:05:15.540153   54148 checks.go:381] validating the presence of executable nsenter
I0124 09:05:15.540165   54148 checks.go:381] validating the presence of executable ebtables
I0124 09:05:15.540180   54148 checks.go:381] validating the presence of executable ethtool
I0124 09:05:15.540193   54148 checks.go:381] validating the presence of executable socat
I0124 09:05:15.540293   54148 checks.go:381] validating the presence of executable tc
I0124 09:05:15.540308   54148 checks.go:381] validating the presence of executable touch
I0124 09:05:15.540322   54148 checks.go:523] running all checks
I0124 09:05:15.541409   54148 kernel_validator.go:81] Validating kernel version
I0124 09:05:15.541555   54148 kernel_validator.go:96] Validating kernel config
I0124 09:05:15.563825   54148 checks.go:411] checking whether the given node name is reachable using net.LookupHost
I0124 09:05:15.563854   54148 checks.go:622] validating kubelet version
I0124 09:05:15.670430   54148 checks.go:138] validating if the service is enabled and active
I0124 09:05:15.678891   54148 checks.go:216] validating availability of port 10250
I0124 09:05:15.678946   54148 checks.go:216] validating availability of port 2379
I0124 09:05:15.678979   54148 checks.go:253] validating the existence and emptiness of directory /var/lib/etcd
[preflight/images] Pulling images required for setting up a Kubernetes cluster
[preflight/images] This might take a minute or two, depending on the speed of your internet connection
[preflight/images] You can also perform this action in beforehand using 'kubeadm config images pull'
I0124 09:05:15.679161   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/kube-apiserver-amd64:v1.11.10
I0124 09:05:15.691389   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/kube-controller-manager-amd64:v1.11.10
I0124 09:05:15.703762   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/kube-scheduler-amd64:v1.11.10
I0124 09:05:15.716211   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.10
I0124 09:05:15.728333   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/pause:3.1
I0124 09:05:15.743046   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/etcd-amd64:3.2.18
I0124 09:05:15.757791   54148 checks.go:840] pulling  registry.aliyuncs.com/google_containers/coredns:1.1.3
I0124 09:05:15.773290   54148 init.go:289] [init] Getting certificates directory from configuration
I0124 09:05:15.773324   54148 init.go:299] Stopping the kubelet
[kubelet] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0124 09:05:15.843326   54148 init.go:317] Starting the kubelet
[preflight] Activating the kubelet service
I0124 09:05:15.932469   54148 init.go:329] [init] creating PKI Assets
I0124 09:05:15.932648   54148 certs.go:37] creating PKI assets
I0124 09:05:15.932677   54148 certs.go:73] create a new self signed cluster CA certificate and key files
[certificates] Using the existing ca certificate and key.
I0124 09:05:16.238189   54148 certs.go:91] creating a new certificate and key files for the apiserver
[certificates] Using the existing apiserver certificate and key.
I0124 09:05:16.526647   54148 certs.go:115] creating a new certificate for kubelets calling apiserver
[certificates] Using the existing apiserver-kubelet-client certificate and key.
I0124 09:05:16.745050   54148 certs.go:253] creating a new public/private key files for signing service account users
[certificates] Using the existing sa key.
I0124 09:05:16.880422   54148 certs.go:272] creating a self signed front proxy CA certificate and key files
[certificates] Using the existing front-proxy-ca certificate and key.
I0124 09:05:16.972465   54148 certs.go:290] creating a new certificate for proxy server client
[certificates] Using the existing front-proxy-client certificate and key.
I0124 09:05:17.095137   54148 certs.go:140] creating a self signed etcd CA certificate and key files
[certificates] Using the existing etcd/ca certificate and key.
I0124 09:05:17.393198   54148 certs.go:158] creating a new server certificate and key files for etcd
[certificates] Using the existing etcd/server certificate and key.
I0124 09:05:17.642749   54148 certs.go:182] creating a new certificate and key files for etcd peering
[certificates] Using the existing etcd/peer certificate and key.
[certificates] Using the existing etcd/healthcheck-client certificate and key.
I0124 09:05:18.126095   54148 certs.go:230] creating a new client certificate for the apiserver calling etcd
[certificates] Using the existing apiserver-etcd-client certificate and key.
[certificates] valid certificates and keys now exist in "/etc/kubernetes/pki"
I0124 09:05:18.218840   54148 init.go:335] [init] generating kubeconfig files
I0124 09:05:18.218846   54148 kubeconfig.go:65] creating all kubeconfig files
[kubeconfig] Using existing up-to-date KubeConfig file: "/etc/kubernetes/admin.conf"
[kubeconfig] Using existing up-to-date KubeConfig file: "/etc/kubernetes/kubelet.conf"
[kubeconfig] Using existing up-to-date KubeConfig file: "/etc/kubernetes/controller-manager.conf"
[kubeconfig] Using existing up-to-date KubeConfig file: "/etc/kubernetes/scheduler.conf"
I0124 09:05:19.263597   54148 init.go:364] [init] bootstraping the control plane
I0124 09:05:19.263604   54148 init.go:365] [init] creating static pod manifest
I0124 09:05:19.263608   54148 manifests.go:44] [controlplane] creating static pod files
I0124 09:05:19.263618   54148 manifests.go:117] [controlplane] getting StaticPodSpecs
[controlplane] wrote Static Pod manifest for component kube-apiserver to "/etc/kubernetes/manifests/kube-apiserver.yaml"
[controlplane] wrote Static Pod manifest for component kube-controller-manager to "/etc/kubernetes/manifests/kube-controller-manager.yaml"
[controlplane] wrote Static Pod manifest for component kube-scheduler to "/etc/kubernetes/manifests/kube-scheduler.yaml"
I0124 09:05:19.270172   54148 init.go:371] [init] no external etcd found. Creating manifest for local etcd static pod
I0124 09:05:19.270180   54148 local.go:40] creating local etcd static pod manifest file
[etcd] Wrote Static Pod manifest for a local etcd instance to "/etc/kubernetes/manifests/etcd.yaml"
I0124 09:05:19.271122   54148 init.go:386] creating Kubernetes client
I0124 09:05:19.273855   54148 init.go:393] [init] waiting for the API server to be healthy
[init] waiting for the kubelet to boot up the control plane as Static Pods from directory "/etc/kubernetes/manifests"
[init] this might take a minute or longer if the control plane images have to be pulled
[apiclient] All control plane components are healthy after 12.001918 seconds
I0124 09:05:31.275916   54148 init.go:421] [init] uploading currently used configuration to the cluster
[uploadconfig] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0124 09:05:31.284096   54148 init.go:426] [init] creating kubelet configuration configmap
[kubelet] Creating a ConfigMap "kubelet-config-1.11" in namespace kube-system with the configuration for the kubelets in the cluster
I0124 09:05:31.296667   54148 init.go:432] [init] marking the master with right label
[markmaster] Marking the node ubuntu as master by adding the label "node-role.kubernetes.io/master=''"
[markmaster] Marking the node ubuntu as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]
I0124 09:05:31.806905   54148 init.go:437] [init] preserving the crisocket information for the master
[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "ubuntu" as an annotation
[bootstraptoken] using token: f5173m.fcy4nbvitvk17gg7
I0124 09:05:32.313348   54148 init.go:469] [init] creating RBAC rules to generate default bootstrap token
I0124 09:05:32.320056   54148 init.go:474] [init] creating RBAC rules to allow bootstrap tokens to post CSR
[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0124 09:05:32.323986   54148 init.go:479] [init] creating RBAC rules to automatic approval of CSRs automatically
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0124 09:05:32.326073   54148 init.go:485] [init] creating/updating RBAC rules for rotating certificate
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0124 09:05:32.328398   54148 init.go:491] [init] creating bootstrap configmap
[bootstraptoken] creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0124 09:05:32.328413   54148 clusterinfo.go:45] [bootstraptoken] loading admin kubeconfig
I0124 09:05:32.328832   54148 clusterinfo.go:53] [bootstraptoken] copying the cluster from admin.conf to the bootstrap kubeconfig
I0124 09:05:32.334123   54148 clusterinfo.go:65] [bootstraptoken] creating/updating ConfigMap in kube-public namespace
I0124 09:05:32.338367   54148 init.go:495] [init] creating ClusterInfo RBAC rules
I0124 09:05:32.338393   54148 clusterinfo.go:79] creating the RBAC rules for exposing the cluster-info ConfigMap in the kube-public namespace
I0124 09:05:32.345581   54148 init.go:500] [init] ensuring DNS addon
[addons] Applied essential addon: CoreDNS
I0124 09:05:32.400317   54148 init.go:505] [init] ensuring proxy addon
I0124 09:05:32.507609   54148 request.go:485] Throttling request took 107.219057ms, request: POST:https://192.168.31.73:6443/api/v1/namespaces/kube-system/serviceaccounts
I0124 09:05:32.707576   54148 request.go:485] Throttling request took 195.270152ms, request: POST:https://192.168.31.73:6443/api/v1/namespaces/kube-system/configmaps
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join 192.168.31.73:6443 --token f5173m.fcy4nbvitvk17gg7 --discovery-token-ca-cert-hash sha256:e5931cc9946c88512cb1999b82ed98a8e869585445d50624dbb3eb7ea8622d44
```

配置 kube ：

```
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

```
# kubectl get nodes
NAME      STATUS     ROLES     AGE       VERSION
ubuntu    NotReady   master    9m        v1.11.3
```

```
# kubectl describe node master
runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized
```

```
# kubectl get pods -n kube-system
NAME                             READY     STATUS    RESTARTS   AGE
coredns-54b65f9c9c-5v8gh         0/1       Pending   0          14m
coredns-54b65f9c9c-86v6q         0/1       Pending   0          14m
etcd-ubuntu                      1/1       Running   0          13m
kube-apiserver-ubuntu            1/1       Running   4          13m
kube-controller-manager-ubuntu   1/1       Running   0          13m
kube-proxy-ngr9p                 1/1       Running   0          14m
kube-scheduler-ubuntu            1/1       Running   0          13m
```

coredns 状态为 Pending。

安装网络插件 weave-net

https://www.weave.works/docs/net/latest/kubernetes/kube-addon/

```
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
```

k8s 支持的网络插件：

https://kubernetes.io/docs/concepts/cluster-administration/addons/

```
# kubectl describe pod -n kube-system weave-net-4w9kw

Events:
  Type    Reason   Age               From             Message
  ----    ------   ----              ----             -------
  Normal  Pulling  2m                kubelet, ubuntu  pulling image "weaveworks/weave-kube:latest"
  Normal  Pulled   1m                kubelet, ubuntu  Successfully pulled image "weaveworks/weave-kube:latest"
  Normal  Created  1m                kubelet, ubuntu  Created container
  Normal  Started  1m                kubelet, ubuntu  Started container
  Normal  Pulling  1m                kubelet, ubuntu  pulling image "weaveworks/weave-npc:latest"
  Normal  Created  24s               kubelet, ubuntu  Created container
  Normal  Started  24s               kubelet, ubuntu  Started container
  Normal  Pulled   24s               kubelet, ubuntu  Successfully pulled image "weaveworks/weave-npc:latest"
  Normal  Pulling  23s (x2 over 1m)  kubelet, ubuntu  pulling image "weaveworks/weave-kube:latest"
  Normal  Created  18s (x2 over 1m)  kubelet, ubuntu  Created container
  Normal  Started  18s (x2 over 1m)  kubelet, ubuntu  Started container
  Normal  Pulled   18s (x2 over 1m)  kubelet, ubuntu  Successfully pulled image "weaveworks/weave-kube:latest"
```

# kubectl get pods -n kube-system
NAME                             READY     STATUS    RESTARTS   AGE
coredns-54b65f9c9c-5v8gh         1/1       Running   0          29m
coredns-54b65f9c9c-86v6q         1/1       Running   0          29m
etcd-ubuntu                      1/1       Running   0          28m
kube-apiserver-ubuntu            1/1       Running   4          28m
kube-controller-manager-ubuntu   1/1       Running   0          28m
kube-proxy-ngr9p                 1/1       Running   0          29m
kube-scheduler-ubuntu            1/1       Running   0          28m
weave-net-4w9kw                  2/2       Running   1          5m


> 感悟：折腾了4天，终于完成 Kubernetes Master 的部署了，真TM不容易啊！主要就是设置好国内镜像和解决软件版本兼容的问题。

学习来源： 极客时间 https://time.geekbang.org/column/intro/100015201?tab=catalog

