### 《深入剖析 Kubernetes》学习笔记 Day 10

今天继续学习Kubernetes集群搭建与实践 (3讲)的第2讲，「从 0 到 1 搭建一个完整的 Kubernetes 集群」。

#### 前文回顾

几经折腾完成 Kubernetes Master 的部署，主要就是设置好国内镜像和解决软件版本兼容的问题。

#### 部署 Kubernetes 的 Worker 节点

把之前安装好 Master 的虚拟机克隆了一个副本。

```
# 修改主机名
hostnamectl set-hostname k8worker
```

来吧，加入 worker 节点！

```
# kubeadm join 192.168.31.73:6443 --token f5173m.fcy4nbvitvk17gg7 --discovery-token-ca-cert-hash sha256:e5931cc9946c88512cb1999b82ed98a8e869585445d50624dbb3eb7ea8622d44
```

果然没那么简单，报错：

```
[preflight] running pre-flight checks
	[WARNING RequiredIPVSKernelModulesAvailable]: the IPVS proxier will not be used, because the following required kernel modules are not loaded: [ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh] or no builtin kernel ipvs support: map[ip_vs:{} ip_vs_rr:{} ip_vs_wrr:{} ip_vs_sh:{} nf_conntrack_ipv4:{}]
you can solve this problem with following methods:
 1. Run 'modprobe -- ' to load missing kernel modules;
2. Provide the missing builtin kernel ipvs support

I0125 08:55:03.790651    5225 kernel_validator.go:81] Validating kernel version
I0125 08:55:03.790953    5225 kernel_validator.go:96] Validating kernel config
	[WARNING Hostname]: hostname "k8worker" could not be reached
	[WARNING Hostname]: hostname "k8worker" lookup k8worker on 192.168.31.1:53: no such host
[preflight] Some fatal errors occurred:
	[ERROR FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists
	[ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists
	[ERROR Swap]: running with swap on is not supported. Please disable swap
```

重置 kubeadm

```
# kubeadm reset
[reset] WARNING: changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.
[reset] are you sure you want to proceed? [y/N]: y
[preflight] running pre-flight checks
[reset] stopping the kubelet service
[reset] unmounting mounted directories in "/var/lib/kubelet"
[reset] removing kubernetes-managed containers
[reset] cleaning up running containers using crictl with socket /var/run/dockershim.sock
[reset] failed to list running pods using crictl: exit status 1. Trying to use docker instead[reset] no etcd manifest found in "/etc/kubernetes/manifests/etcd.yaml". Assuming external etcd
[reset] deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes]
[reset] deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
[reset] deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
```

再来！

```
# kubeadm join 192.168.31.73:6443 --token f5173m.fcy4nbvitvk17gg7 --discovery-token-ca-cert-hash sha256:e5931cc9946c88512cb1999b82ed98a8e869585445d50624dbb3eb7ea8622d44
```

ok了。

```
# kubectl get nodes
NAME       STATUS    ROLES     AGE       VERSION
k8worker   Ready     <none>    2m        v1.11.3
ubuntu     Ready     master    23h       v1.11.3
```

#### 部署 Dashboard 可视化插件

提供一个可视化的 Web 界面来查看当前集群的各种信息。

```
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc6/aio/deploy/recommended.yaml
```

```
# kubectl get pods --all-namespaces

NAMESPACE              NAME                                        READY     STATUS    RESTARTS   AGE

kubernetes-dashboard   dashboard-metrics-scraper-878cb9dc4-wjwlg   1/1       Running   0          1m
kubernetes-dashboard   kubernetes-dashboard-5bc5dbff7f-mw89n       1/1       Running   0          1m
```

#### 部署容器存储插件

持久化存储：在容器里挂载一个基于网络或者其他机制的远程数据卷，使得在容器里创建的文件，实际上是保存在远程存储服务器上，或者以分布式的方式保存在多个节点上，而与当前宿主机没有任何绑定关系。这样，无论在哪个宿主机上启动新的容器，都可以请求挂载指定的持久化存储卷，从而访问到数据卷里保存的内容。

> 感悟：很简单的操作步骤，因为上网问题搞得如此复杂。啊！悲哀的人…

学习来源： 极客时间 https://time.geekbang.org/column/intro/100015201?tab=catalog



